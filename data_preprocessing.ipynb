{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import cv2\n",
    "import numpy as np\n",
    "from natsort import natsorted\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_large_contours(image, binary_mask, area_threshold):\n",
    "    # Detect contours in the binary mask\n",
    "    contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    \n",
    "    # Return the original mask if no contours are found\n",
    "    if not contours:\n",
    "        return binary_mask\n",
    "    \n",
    "    # Find the largest contour by area\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    \n",
    "    # Fill the largest contour if its area exceeds the threshold\n",
    "    if cv2.contourArea(largest_contour) > area_threshold:\n",
    "        mask = np.zeros_like(binary_mask)\n",
    "        cv2.drawContours(mask, [largest_contour], -1, 255, thickness=cv2.FILLED)\n",
    "        return mask\n",
    "    else:\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def center_and_scale(img, mask, desired_size=None):\n",
    "    # Find contours in the mask\n",
    "    contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return img  # Return original if no contours found\n",
    "\n",
    "    # Calculate the combined bounding box around all contours\n",
    "    min_x, min_y = img.shape[1], img.shape[0]\n",
    "    max_x = max_y = 0\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv2.boundingRect(c)\n",
    "        min_x, min_y = min(x, min_x), min(y, min_y)\n",
    "        max_x, max_y = max(x + w, max_x), max(y + h, max_y)\n",
    "    \n",
    "    # Crop the original image around the combined bounding box\n",
    "    cropped_img = img[min_y:max_y, min_x:min_x]\n",
    "\n",
    "    # Use original image size if desired_size is not specified\n",
    "    if desired_size is None:\n",
    "        desired_size = img.shape[:2]\n",
    "\n",
    "    # Calculate the scaling factor while maintaining the aspect ratio\n",
    "    h, w = cropped_img.shape[:2]\n",
    "    aspect_ratio = w / h\n",
    "    desired_h, desired_w = desired_size\n",
    "    if desired_w / desired_h > aspect_ratio:\n",
    "        new_h = desired_h\n",
    "        new_w = int(aspect_ratio * new_h)\n",
    "    else:\n",
    "        new_w = desired_w\n",
    "        new_h = int(new_w / aspect_ratio)\n",
    "\n",
    "    # Scale the cropped image to the new size\n",
    "    scaled_img = cv2.resize(cropped_img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "\n",
    "    # Create a new blank image with the desired size\n",
    "    if len(img.shape) == 2:  # Grayscale image\n",
    "        final_img = np.zeros((desired_h, desired_w), dtype=img.dtype)\n",
    "    else:  # Color image\n",
    "        final_img = np.zeros((desired_h, desired_w, img.shape[2]), dtype=img.dtype)\n",
    "    \n",
    "    # Centre the scaled image on the new blank image\n",
    "    x_offset = (desired_w - new_w) // 2\n",
    "    y_offset = (desired_h - new_h) // 2\n",
    "    final_img[y_offset:y_offset + new_h, x_offset:x_offset + new_w] = scaled_img\n",
    "\n",
    "    return final_img\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2482\n"
     ]
    }
   ],
   "source": [
    "folder_path = './data/sub_files/A1_50kV'\n",
    "file_names = natsorted(os.listdir(folder_path))  # Cut off first and last 200 images to remove empty images\n",
    "print(len(file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CT Scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:   0%|          | 0/1201 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images:  79%|███████▉  | 954/1201 [02:24<00:28,  8.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unable to load image: C1_50kV_1103.png\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 1201/1201 [03:00<00:00,  6.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 0 images due to small thresholded area.\n",
      "Contour 0 images skipped.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Define the folder paths\n",
    "folder_path = './data/sub_files/C1_50kV'\n",
    "output_path = './data/preproc/C1_50kV'\n",
    "\n",
    "# List all files and select the required sample\n",
    "file_names = natsorted(os.listdir(folder_path))[150:-150]  # Cut off first and last 150 images\n",
    "\n",
    "# Create the output directory if it doesn't exist\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Initialize counters for skipped images\n",
    "skipped_images = 0\n",
    "contour_skip = 0\n",
    "\n",
    "# Iterate through all selected files\n",
    "for filename in tqdm(file_names, desc='Processing images'):\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    processed_file_path = os.path.join(output_path, filename)\n",
    "\n",
    "    if os.path.isfile(file_path):\n",
    "        # Load the image\n",
    "        image = cv2.imread(file_path, cv2.IMREAD_GRAYSCALE)\n",
    "        if image is not None:\n",
    "            # Apply a global threshold to isolate the circular area\n",
    "            _, thresholded = cv2.threshold(image, 42, 255, cv2.THRESH_BINARY)   # set this threshold depending on the input data (values used: 50, 22, 42)\n",
    "\n",
    "            # Skip this image if the thresholded area is less than 9000\n",
    "            if cv2.countNonZero(thresholded) < 9000:\n",
    "                skipped_images += 1\n",
    "                continue\n",
    "\n",
    "            # Use dilation to enlarge the regions within the threshold\n",
    "            kernel = np.ones((5, 5), np.uint8)\n",
    "            dilated_image = cv2.dilate(thresholded, kernel, iterations=3)\n",
    "\n",
    "            filled = fill_large_contours(image, dilated_image, 25000)\n",
    "            if filled is None:\n",
    "                contour_skip += 1\n",
    "                continue\n",
    "\n",
    "            # Apply morphological operations to clean the mask\n",
    "            cleaned = cv2.morphologyEx(filled, cv2.MORPH_OPEN, kernel, iterations=2)\n",
    "            closing = cv2.morphologyEx(cleaned, cv2.MORPH_CLOSE, kernel, iterations=3)\n",
    "\n",
    "            # Apply Gaussian blurring to the cleaned image\n",
    "            blurred = cv2.GaussianBlur(closing, (15, 15), 0)\n",
    "            blurred_filled = fill_large_contours(image, blurred, 20000)\n",
    "\n",
    "            # Mask the original image with the processed mask\n",
    "            result_img = cv2.bitwise_and(image, image, mask=blurred_filled)\n",
    "            result_img = center_and_scale(result_img, blurred_filled, (512, 512))\n",
    "\n",
    "            # Save the processed image\n",
    "            cv2.imwrite(processed_file_path, result_img)\n",
    "        else:\n",
    "            print(f\"Unable to load image: {filename}\")\n",
    "\n",
    "# Print summary of skipped images\n",
    "print(f\"Skipped {skipped_images} images due to small thresholded area.\")\n",
    "print(f\"Skipped {contour_skip} images due to insufficient contour area.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histology scans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing images: 100%|██████████| 656/656 [00:36<00:00, 18.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipped 41 images with white backgrounds.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def process_images(input_folder, output_folder, prefix='', desired_size=(512, 512)):\n",
    "    # Create the output directory if it does not exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    \n",
    "    # Counter for skipped images\n",
    "    skipped_count = 0\n",
    "    \n",
    "    # Get a list of all image files in the input folder\n",
    "    image_files = [f for f in os.listdir(input_folder) if f.endswith(('.jpg', '.jpeg', '.png', '.bmp', '.tiff'))]\n",
    "    \n",
    "    for image_file in tqdm(image_files, desc=\"Processing images\"):\n",
    "        image_path = os.path.join(input_folder, image_file)\n",
    "        img = cv2.imread(image_path)\n",
    "        \n",
    "        if img is None:\n",
    "            print(f\"Failed to read {image_path}\")\n",
    "            continue\n",
    "        \n",
    "        # Check if the background is white (top-left corner)\n",
    "        if np.all(img[0, 0] == [255, 255, 255]):\n",
    "            skipped_count += 1\n",
    "            continue\n",
    "        \n",
    "        h, w = img.shape[:2]\n",
    "        scale = min(desired_size[0] / h, desired_size[1] / w)\n",
    "        \n",
    "        # Resize the image if it's larger than the desired size\n",
    "        if h > desired_size[0] or w > desired_size[1]:\n",
    "            new_h, new_w = int(h * scale), int(w * scale)\n",
    "            img = cv2.resize(img, (new_w, new_h), interpolation=cv2.INTER_AREA)\n",
    "        else:\n",
    "            new_h, new_w = h, w\n",
    "        \n",
    "        # Calculate padding to center the image\n",
    "        top_pad = (desired_size[0] - new_h) // 2\n",
    "        bottom_pad = desired_size[0] - new_h - top_pad\n",
    "        left_pad = (desired_size[1] - new_w) // 2\n",
    "        right_pad = desired_size[1] - new_w - left_pad\n",
    "        \n",
    "        # Apply padding to center the image\n",
    "        padded_img = cv2.copyMakeBorder(img, top_pad, bottom_pad, left_pad, right_pad, cv2.BORDER_CONSTANT, value=[0, 0, 0])\n",
    "        \n",
    "        # Save the processed image with the specified prefix\n",
    "        output_path = os.path.join(output_folder, f\"{prefix}{image_file}\")\n",
    "        cv2.imwrite(output_path, padded_img)\n",
    "    \n",
    "    print(f\"Skipped {skipped_count} images with white backgrounds.\")\n",
    "\n",
    "# Define input and output folders and prefix\n",
    "input_folder = './data/hist/ts19_EMA65'\n",
    "output_folder = './data/preproc/TS19'\n",
    "prefix = 'TS19_'\n",
    "\n",
    "# Process the images\n",
    "process_images(input_folder, output_folder, prefix=prefix, desired_size=(512, 512))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
